# Evaluace RAG systémů a LLM na češtině / RAG system and LLM evaluation on Czech texts

### Abstrakt / abstract
Práce se zabývá návrhem a evaluací systému Retrieval-Augmented Generation (RAG) pracujícího s
českými texty. V teoretické části práce jsou vymezeny klíčové koncepty z oblasti zpracování přirozeného
jazyka, neuronových sítí a umělé inteligence. Dále je objasněna role metod, jako je fine-tuning,
promptování, chunking a využití vektorových databází v kontextu systémů RAG. Cílem experimentální
části práce je otestovat schopnosti embedding modelů při vektorizaci českých textů a vyhodnotit, s jakou
přesností lze ve vektorové databázi na základě sémantické podobnosti nalézat relevantní texty správně
zodpovídající zadané otázky. Dva nejpřesnější modely – jeden placený a jeden bezplatný – jsou následně
integrovány do systému RAG, kde jsou otestovány v kombinaci se dvěma generativními jazykovými
modely. Cílem je zjistit, zda tyto modely dokážou generovat správné odpovědi na otázky na základě
relevantních textů získaných z databáze, a zda může být systém RAG používající češtinu dostatečně
efektivní pro praktické využití.

---

The aim of this thesis is to design and evaluate a Retrieval-Augmented Generation (RAG) system using
Czech texts. The theoretical part of the thesis defines key concepts in the field of natural language
processing, neural networks and artificial intelligence. Further on, the role of methods such as fine-
tuning, prompting, chunking and the use of vector databases in the context of RAG systems is explained.
The aim of the experimental part of the thesis is to test the capability of the embedding models in
vectorizing Czech texts and to evaluate the accuracy with which relevant texts correctly answering the
given questions can be found in the vector database based on semantic similarity. The two most accurate
models – one paid and one free – are then integrated into the RAG system, where they are tested in
combination with two generative language models. The aim is to determine whether these models can
generate correct answers to questions based on the relevant texts retrieved from the database, and
whether a RAG system using Czech can be effective enough for practical use.


## Dataset
Dataset obsahuje 20 smyšlených novinových článků vygenerovaných pomocí ChatGPT. Texty byly rozděleny na chunky o maximální velikosti 128 slov. Každému textu byla přiřazena jedna 
otázka, na niž lze odpovědět na základě jednoho z jeho chunků.

---

The dataset contains 20 fictional newspaper articles generated by ChatGPT. The texts were divided into chunks with maximum length of 128 words. Each text was assigned one
question, which can be answered based on one of its chunks.

## Srovnání embedding modelů / embedding models comparison
Skript *pt2_db.ipynb* umožňuje automatizované vyhodnocování přesnosti vyhledávání relevantních dokumentů ve vektorové databázi ChromaDB. 
Tím vznikla opakovatelná metoda pro výběr nejpřesnějšího embedding modelu pro libovolná textová data.

Celkový počet textů a jim náležejících otázek byl 20. Při každé shodě správně odpovídajícího textu s textem nalezeným mezi prvními nejpodobnějšími texty 
byla přesnost pro daný model zvýšena o 5 % podle toho, na jakém ranku (1.–5.) se nalezený text vyskytl.

Tabulka a graf prezentují výsledky měření. Lze v nich pozorovat výrazný propad přesnosti u bezplatných modelů a zároveň skutečnost, že fastText model dosáhl 
vyšší přesnosti než většina bezplatných vícejazyčných transformátorů. Z výsledků zároveň vyplývá, že existuje středně silný pozitivní vztah mezi přesností modelů a 
počtem dimenzí.

---

The *pt2_db.ipynb* script provides a way for automated evaluation of retrieval accuracy for searching relevant documents in the ChromaDB vector database.
It is a repeatable method that enables selecting the most accurate embedding model for any text data.

The total number of texts and questions was 20. For each match of a text marked as correct with a text found among the first most similar texts,
the accuracy for the given model increased by 5% depending on the rank (1–5) at which the found text occurred.

The table and graph present the results. They show a significant drop in accuracy for free models and the fact that the fastText model achieved
higher accuracy than most free multilingual transformers. The results also show that there is a moderate relationship between the models' accuracy and
vector sizes.

#### Výsledky / results
|     Free    |     Model                                                  |     Dimensions    |     TOP 1    |     TOP 3    |     TOP 5    |
|---------------|------------------------------------------------------------|----------------|--------------|--------------|--------------|
|               |     OpenAI:   text-embedding-3-large                       |     3072       |     60%      |     100%     |     100%     |
|               |     Jina:   jina-embeddings-v3                             |     1024       |     55%      |     90%      |     100%     |
|               |     OpenAI:   text-embedding-3-small                       |     1536       |     55%      |     85%      |     95%      |
|               |     Jina:   jina-clip-v2                                   |     1024       |     55%      |     85%      |     95%      |
|               |     Google   Vertex AI: text-multilingual-embedding-002    |     3072       |     45%      |     85%      |     95%      |
|               |     Cohere:   embed-multilingual-light-v3.0                |     384        |     30%      |     80%      |     95%      |
|               |     OpenAI:   text-embedding-ada-002                       |     1536       |     55%      |     75%      |     95%      |
|               |     Cohere:   embed-multilingual-v3.0                      |     1024       |     35%      |     60%      |     85%      |
|     ✓         |     paraphrase-multilingual-mpnet-base-v2                  |     768        |     20%      |     50%      |     70%      |
|     ✓         |     fastText                                               |     300        |     10%      |     45%      |     65%      |
|     ✓         |     paraphrase-multilingual-MiniLM-L12-v2                  |     384        |     25%      |     55%      |     60%      |
|     ✓         |     NomicAI:   nomic-embed-text                            |     768        |     20%      |     40%      |     50%      |
|     ✓         |     distiluse-base-multilingual-cased-v2                   |     512        |     15%      |     25%      |     50%      |
|     ✓         |     multi-qa-distilbert-cos-v1                             |     768        |     30%      |     40%      |     45%      |
|     ✓         |     multi-qa-mpnet-base-dot-v1                             |     768        |     15%      |     30%      |     45%      |
|     ✓         |     distiluse-base-multilingual-cased-v1                   |     512        |     10%      |     40%      |     40%      |
|     ✓         |     MixedBreadAI:   mxbai-embed-large                      |     512        |     0%       |     25%      |     40%      |
|     ✓         |     multi-qa-MiniLM-L6-cos-v1                              |     384        |     15%      |     25%      |     35%      |
|               |     Google:   text-embedding-004                           |     768        |     5%       |     20%      |     35%      |
|     ✓         |     all-MiniLM-L6-v2                                       |     384        |     15%      |     25%      |     30%      |
|               |     Cohere:   embed-multilingual-v2.0                      |     768        |     0%       |     5%       |     30%      |
|     ✓         |     Snowflake: snowflake-arctic-embed                      |     1024       |     10%      |     20%      |     25%      |

<img width="700" alt="image" src="https://github.com/user-attachments/assets/338c2941-3f49-4498-bd30-74fe48d6610a" />

## RAG test
Na základě výsledků byl pro retrieval komponentu systému RAG vybrán placený model text-embedding-3-large od OpenAI a bezplacený model paraphrase-multilingual-mpnet-base-v2.
Pro generativní komponentu byl zvolen placený GPT-4o mini od OpenAI a bezplatný Llama 3.3 70B Instruct Turbo od Mety.

V testu systému RAG byly pomocí čtyř kombinací modelů postupně vygenerovány odpovědi na všechny předem definované otázky na základě kontextu (tři nejpodobnější nalezené texty) poskytnutého vektorovou databází při retrievalu. 
Skripty pt2_rag_v2 lze po úpravě použít pro testování libovolných modelů. Test byl proveden při použití chunků textů a následně při použití celých textů.

Po vygenerování odpovědí proběhla kvalitativní analýza, v rámci níž byla hodnocena míra správnosti (případně chybovosti) vygenerovaných odpovědí na základě porovnání 
jejich obsahu a významů se správnými chunky textů. Odpovědi byly ohodnoceny na základě předem definované bodové škály.

---

Based on the results, the paid model text-embedding-3-large from OpenAI and the free model paraphrase-multilingual-mpnet-base-v2 were selected for the retrieval part of the RAG system.
The paid GPT-4o mini from OpenAI and the free Llama 3.3 70B Instruct Turbo from Meta were selected for the generative part.

In the RAG system test, answers to all predefined questions were generated using four model combinations based on the context (the three most similar texts found) provided by the vector database during retrieval.
The pt2_rag_v2 scripts can be used to test any models after modification. The test was performed using text chunks and then full texts.

After generating the answers, a qualitative analysis was performed, in which the correctness (or error rate) of the generated answers was evaluated based on a comparison of
their content and meaning with the correct text chunks. The answers were scored based on a predefined scoring scale.

#### Chunky / chunks
|     Embedding     |     LLM      |     Obsah    |     Název    |     Bonus    |     Chyba    |     Celkem    |     Skóre      |
|-------------------|--------------|--------------|--------------|--------------|--------------|---------------|----------------|
|     OpenAI        |     GPT      |     14,3     |     3,0      |     1,4      |     -0,1     |     18,6      |     89,42 %    |
|     OpenAI        |     Llama    |     11,9     |     3,5      |     2,5      |     0,0      |     17,9      |     86,06 %    |
|     Paraphrase    |     Llama    |     9,7      |     2,0      |     3,0      |     -0,7     |     14,0      |     67,31 %    |
|     Paraphrase    |     GPT      |     9,5      |     2,0      |     2,6      |     -0,9     |     13,2      |     63,46 %    |

#### Celé texty / whole texts
|     Embedding    |     LLM      |     Obsah    |     Název    |     Bonus    |     Chyba    |     Celkem    |     Skóre      |
|------------------|--------------|--------------|--------------|--------------|--------------|---------------|----------------|
|     OpenAI       |     Llama    |     12,7     |     3,6      |     2,1      |     0,0      |     18,4      |     88,46 %    |
|                  |     GPT      |     12,4     |     3,0      |     1,5      |     -0,5     |     16,4      |     78,85 %    |
